{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c254ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Face Restoration with Transformer-based Model\n",
    "This script implements a face restoration model using a transformer-based architecture. \n",
    "It includes data loading, augmentation, degradation, model definition, training, validation, and inference.\n",
    "It is designed to work with the FFHQ dataset and includes functionality for generating landmark heatmaps, applying degradation, and computing perceptual loss.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tqdm import tqdm\n",
    "import mediapipe as mp\n",
    "import logging\n",
    "import cv2\n",
    "import torchvision.models as models\n",
    "import random\n",
    "import math\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Verify GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logger.info(f\"Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
    "\n",
    "# Utility Functions\n",
    "class FileClient:\n",
    "    def __init__(self, backend='disk'):\n",
    "        self.backend = backend\n",
    "\n",
    "    def get(self, filepath):\n",
    "        if self.backend == 'disk':\n",
    "            with open(filepath, 'rb') as f:\n",
    "                return f.read()\n",
    "        raise NotImplementedError(f\"Backend {self.backend} not supported\")\n",
    "\n",
    "def imfrombytes(content, float32=False):\n",
    "    img_np = cv2.imdecode(np.frombuffer(content, np.uint8), cv2.IMREAD_COLOR)\n",
    "    img_np = cv2.cvtColor(img_np, cv2.COLOR_BGR2RGB)\n",
    "    if float32:\n",
    "        img_np = img_np.astype(np.float32) / 255.0\n",
    "    return img_np\n",
    "\n",
    "def img2tensor(img, bgr2rgb=False, float32=True):\n",
    "    if img.shape[2] == 3 and bgr2rgb:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = torch.from_numpy(img.transpose(2, 0, 1))\n",
    "    if float32:\n",
    "        img = img.float() / 255.0\n",
    "    return img\n",
    "\n",
    "def augment(img, hflip=True, rotation=True):\n",
    "    hflip = hflip and random.random() < 0.5\n",
    "    vflip = rotation and random.random() < 0.5\n",
    "    rot90 = rotation and random.random() < 0.5\n",
    "    if hflip:\n",
    "        img = img[:, ::-1, :]\n",
    "    if vflip:\n",
    "        img = img[::-1, :, :]\n",
    "    if rot90:\n",
    "        img = img.transpose(1, 0, 2)\n",
    "    return img\n",
    "\n",
    "def circular_lowpass_kernel(omega_c, kernel_size):\n",
    "    kernel = np.zeros((kernel_size, kernel_size), dtype=np.float32)\n",
    "    center = kernel_size // 2\n",
    "    for i in range(kernel_size):\n",
    "        for j in range(kernel_size):\n",
    "            r = np.sqrt((i - center) ** 2 + (j - center) ** 2)\n",
    "            if r <= kernel_size // 2:\n",
    "                kernel[i, j] = np.sinc(r * omega_c / np.pi)\n",
    "    kernel /= kernel.sum() or 1.0\n",
    "    return kernel\n",
    "\n",
    "def random_mixed_kernels(kernel_list, kernel_prob, kernel_size, sigma):\n",
    "    kernel_type = np.random.choice(kernel_list, p=kernel_prob)\n",
    "    if kernel_type == 'iso':\n",
    "        sigma_val = np.random.uniform(sigma[0], sigma[1])\n",
    "        kernel = cv2.getGaussianKernel(kernel_size, sigma_val)\n",
    "        kernel = kernel * kernel.T\n",
    "    elif kernel_type == 'aniso':\n",
    "        sigma1 = np.random.uniform(sigma[0], sigma[1])\n",
    "        sigma2 = np.random.uniform(sigma[0], sigma[1])\n",
    "        theta = np.random.uniform(-math.pi, math.pi)\n",
    "        kernel = cv2.getGaussianKernel(kernel_size, sigma1)\n",
    "        kernel = kernel * kernel.T\n",
    "        M = cv2.getRotationMatrix2D((kernel_size // 2, kernel_size // 2), theta * 180 / np.pi, 1)\n",
    "        kernel = cv2.warpAffine(kernel, M, (kernel_size, kernel_size))\n",
    "    kernel /= kernel.sum() or 1.0\n",
    "    return kernel\n",
    "\n",
    "# Dataset Class\n",
    "class FFHQsubDataset(Dataset):\n",
    "    def __init__(self, opt):\n",
    "        super().__init__()\n",
    "        self.opt = opt\n",
    "        self.file_client = FileClient()\n",
    "        self.gt_folder = opt['dataroot_gt']\n",
    "        with open(opt['meta_info']) as f:\n",
    "            self.paths = [os.path.join(self.gt_folder, line.strip()) for line in f]\n",
    "        \n",
    "        self.blur_kernel_size = opt['blur_kernel_size']\n",
    "        self.kernel_list = opt['kernel_list']\n",
    "        self.kernel_prob = opt['kernel_prob']\n",
    "        self.blur_sigma = opt['blur_sigma']\n",
    "        self.sinc_prob = opt['sinc_prob']\n",
    "        self.kernel_range = [2 * v + 1 for v in range(3, 11)]\n",
    "        self.pulse_tensor = torch.zeros(21, 21).float()\n",
    "        self.pulse_tensor[10, 10] = 1\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        gt_path = self.paths[index]\n",
    "        retry = 3\n",
    "        while retry > 0:\n",
    "            try:\n",
    "                img_bytes = self.file_client.get(gt_path)\n",
    "                break\n",
    "            except (IOError, OSError):\n",
    "                index = random.randint(0, len(self.paths) - 1)\n",
    "                gt_path = self.paths[index]\n",
    "                retry -= 1\n",
    "        if retry == 0:\n",
    "            raise RuntimeError(f\"Failed to load image {gt_path}\")\n",
    "\n",
    "        img_gt = imfrombytes(img_bytes, float32=True)\n",
    "        img_gt = augment(img_gt, self.opt['use_hflip'], self.opt['use_rot'])\n",
    "\n",
    "        kernel_size = random.choice(self.kernel_range)\n",
    "        if np.random.uniform() < self.opt['sinc_prob']:\n",
    "            omega_c = np.random.uniform(np.pi / 5, np.pi) if kernel_size >= 13 else np.random.uniform(np.pi / 3, np.pi)\n",
    "            kernel = circular_lowpass_kernel(omega_c, kernel_size)\n",
    "        else:\n",
    "            kernel = random_mixed_kernels(self.kernel_list, self.kernel_prob, kernel_size, self.blur_sigma)\n",
    "        pad_size = (21 - kernel_size) // 2\n",
    "        kernel = np.pad(kernel, ((pad_size, pad_size), (pad_size, pad_size)))\n",
    "\n",
    "        if np.random.uniform() < self.opt['final_sinc_prob']:\n",
    "            kernel_size = random.choice(self.kernel_range)\n",
    "            sinc_kernel = circular_lowpass_kernel(np.random.uniform(np.pi / 3, np.pi), kernel_size)\n",
    "            sinc_kernel = np.pad(sinc_kernel, ((pad_size, pad_size), (pad_size, pad_size)))\n",
    "        else:\n",
    "            sinc_kernel = self.pulse_tensor\n",
    "\n",
    "        img_gt = img2tensor(img_gt, bgr2rgb=True, float32=True)\n",
    "        kernel = torch.FloatTensor(kernel)\n",
    "        sinc_kernel = torch.FloatTensor(sinc_kernel)\n",
    "\n",
    "        return {'gt': img_gt, 'kernel': kernel, 'sinc_kernel': sinc_kernel, 'gt_path': gt_path}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "# Degradation Function\n",
    "def degrade_image(img, kernel, sinc_kernel):\n",
    "    B, C, H, W = img.size()\n",
    "    output = torch.zeros(B, C, 128, 128, device=img.device)\n",
    "    for b in range(B):\n",
    "        k = kernel[b:b+1].unsqueeze(0).repeat(3, 1, 1, 1).to(img.device)\n",
    "        sk = sinc_kernel[b:b+1].unsqueeze(0).repeat(3, 1, 1, 1).to(img.device)\n",
    "        img_b = img[b:b+1]\n",
    "        img_b = F.conv2d(img_b, k, padding=10, groups=3)\n",
    "        img_b = F.interpolate(img_b, scale_factor=0.25, mode='bicubic')\n",
    "        img_b = F.conv2d(img_b, sk, padding=10, groups=3)\n",
    "        img_b = F.interpolate(img_b, size=(128, 128), mode='bicubic').clamp(0, 1)\n",
    "        output[b:b+1] = img_b\n",
    "    return output\n",
    "\n",
    "# Model Definition\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, dim, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.attn = nn.MultiheadAttention(dim, num_heads)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(dim, dim * 2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(dim * 2, dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        x = x.permute(0, 2, 3, 1).reshape(B, H * W, C)\n",
    "        x = x + self.attn(self.norm1(x), self.norm1(x), self.norm1(x))[0]\n",
    "        x = x + self.ffn(self.norm2(x))\n",
    "        return x.reshape(B, H, W, C).permute(0, 3, 1, 2)\n",
    "\n",
    "class LandmarkAttention(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(16, 1, 3, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, landmark_heatmap):\n",
    "        if landmark_heatmap is None:\n",
    "            return self.conv(x)\n",
    "        if landmark_heatmap.size(2) != x.size(2):\n",
    "            landmark_heatmap = F.interpolate(landmark_heatmap, size=(x.size(2), x.size(3)), mode='bilinear')\n",
    "        attention_weights = self.attention(landmark_heatmap)\n",
    "        return self.conv(x * (1 + attention_weights))\n",
    "\n",
    "class PixelShuffleUpsample(nn.Module):\n",
    "    def __init__(self, in_ch, scale=2):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, in_ch * (scale ** 2), 3, padding=1)\n",
    "        self.shuffle = nn.PixelShuffle(scale)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.shuffle(self.conv(x))\n",
    "\n",
    "class FaceRestormer(nn.Module):\n",
    "    def __init__(self, in_ch=3, out_ch=3, dim=64):\n",
    "        super().__init__()\n",
    "        self.initial = nn.Conv2d(in_ch, dim, 3, padding=1)\n",
    "        self.encoder1 = nn.Sequential(TransformerBlock(dim), TransformerBlock(dim))\n",
    "        self.down1 = nn.Conv2d(dim, dim, 4, stride=2, padding=1)\n",
    "        self.encoder2 = TransformerBlock(dim)\n",
    "        self.down2 = nn.Conv2d(dim, dim, 4, stride=2, padding=1)\n",
    "        self.bottleneck = TransformerBlock(dim)\n",
    "        self.up1 = PixelShuffleUpsample(dim, 2)\n",
    "        self.landmark_attention = LandmarkAttention(dim)\n",
    "        self.decoder1 = TransformerBlock(dim)\n",
    "        self.up2 = PixelShuffleUpsample(dim, 2)\n",
    "        self.decoder2 = TransformerBlock(dim)\n",
    "        self.final_upsample = nn.Sequential(\n",
    "            PixelShuffleUpsample(dim, 2),\n",
    "            nn.Conv2d(dim, dim, 3, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            PixelShuffleUpsample(dim, 2),\n",
    "            nn.Conv2d(dim, out_ch, 3, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, landmark_heatmap=None):\n",
    "        feat = self.initial(x)\n",
    "        e1 = self.encoder1(feat)\n",
    "        feat = self.down1(e1)\n",
    "        e2 = self.encoder2(feat)\n",
    "        feat = self.down2(e2)\n",
    "        feat = self.bottleneck(feat)\n",
    "        feat = self.up1(feat)\n",
    "        feat = self.landmark_attention(feat, landmark_heatmap) + e2\n",
    "        feat = self.decoder1(feat)\n",
    "        feat = self.up2(feat) + e1\n",
    "        feat = self.decoder2(feat)\n",
    "        return self.final_upsample(feat)\n",
    "\n",
    "# Landmark Heatmap Generation\n",
    "def generate_landmark_heatmap(image_batch):\n",
    "    mp_face = mp.solutions.face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1)\n",
    "    batch_size = image_batch.size(0)\n",
    "    device = image_batch.device\n",
    "    heatmaps = []\n",
    "    for b in range(batch_size):\n",
    "        img = (image_batch[b].permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)\n",
    "        results = mp_face.process(img)\n",
    "        heatmap = np.zeros((128, 128), dtype=np.float32)\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                for lm in face_landmarks.landmark:\n",
    "                    x, y = int(lm.x * 128), int(lm.y * 128)\n",
    "                    if 0 <= x < 128 and 0 <= y < 128:\n",
    "                        for i in range(max(0, y-2), min(128, y+3)):\n",
    "                            for j in range(max(0, x-2), min(128, x+3)):\n",
    "                                dist = np.sqrt((i-y)**2 + (j-x)**2)\n",
    "                                if dist < 3:\n",
    "                                    heatmap[i, j] = max(heatmap[i, j], np.exp(-dist))\n",
    "        else:\n",
    "            center_x, center_y = 64, 64\n",
    "            for i in range(128):\n",
    "                for j in range(128):\n",
    "                    dist = np.sqrt((i - center_y) ** 2 + (j - center_x) ** 2)\n",
    "                    heatmap[i, j] = np.exp(-dist / 10.0)\n",
    "        heatmaps.append(torch.from_numpy(heatmap))\n",
    "    heatmap_batch = torch.stack(heatmaps).unsqueeze(1).to(device)\n",
    "    mp_face.close()\n",
    "    return heatmap_batch\n",
    "\n",
    "# Perceptual Loss\n",
    "class PerceptualLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        vgg = models.vgg16(weights='IMAGENET1K_V1').features[:16].eval().to(device)\n",
    "        for param in vgg.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.vgg = vgg\n",
    "        self.criterion = nn.L1Loss()\n",
    "\n",
    "    def forward(self, pred, gt):\n",
    "        return self.criterion(self.vgg(pred), self.vgg(gt))\n",
    "\n",
    "# Dataset Configuration\n",
    "dataset_base = \"/content/drive/MyDrive/2024-S2-AI6126-Project2-Release/datasets\"\n",
    "opt = {\n",
    "    'dataroot_gt': '/content/FFHQ/train/GT',\n",
    "    'meta_info': '/content/FFHQ/train/meta_info_FFHQfull_GT.txt',\n",
    "    'use_hflip': True,\n",
    "    'use_rot': True,\n",
    "    'blur_kernel_size': 21,\n",
    "    'kernel_list': ['iso', 'aniso'],\n",
    "    'kernel_prob': [0.45, 0.55],\n",
    "    'blur_sigma': [0.2, 3],\n",
    "    'sinc_prob': 0.1,\n",
    "    'final_sinc_prob': 0.8\n",
    "}\n",
    "\n",
    "# Setup Directories\n",
    "os.makedirs('/content/FFHQ/train/GT', exist_ok=True)\n",
    "os.makedirs('/content/FFHQ/val/GT', exist_ok=True)\n",
    "os.makedirs('/content/FFHQ/val/LQ', exist_ok=True)\n",
    "os.makedirs('/content/FFHQ/test/LQ', exist_ok=True)\n",
    "os.makedirs('/content/results/val', exist_ok=True)\n",
    "os.makedirs('/content/results/test', exist_ok=True)\n",
    "os.makedirs('/content/models', exist_ok=True)\n",
    "\n",
    "# Copy Dataset\n",
    "logger.info(\"Copying dataset to Colab...\")\n",
    "os.system(f\"cp -r {dataset_base}/train/GT/* /content/FFHQ/train/GT/ || echo 'Error copying train GT'\")\n",
    "os.system(f\"cp -r {dataset_base}/val/GT/* /content/FFHQ/val/GT/ || echo 'Error copying val GT'\")\n",
    "os.system(f\"cp -r {dataset_base}/val/LQ/* /content/FFHQ/val/LQ/ || echo 'Error copying val LQ'\")\n",
    "if os.path.exists(f\"{dataset_base}/test/LQ\"):\n",
    "    os.system(f\"cp -r {dataset_base}/test/LQ/* /content/FFHQ/test/LQ/ || echo 'Error copying test LQ'\")\n",
    "else:\n",
    "    logger.warning(f\"Test directory does not exist: {dataset_base}/test/LQ\")\n",
    "\n",
    "# Verify Dataset\n",
    "train_images = len([f for f in os.listdir('/content/FFHQ/train/GT') if f.endswith('.png')])\n",
    "val_gt_images = len([f for f in os.listdir('/content/FFHQ/val/GT') if f.endswith('.png')])\n",
    "val_lq_images = len([f for f in os.listdir('/content/FFHQ/val/LQ') if f.endswith('.png')])\n",
    "test_images = len([f for f in os.listdir('/content/FFHQ/test/LQ') if f.endswith('.png')])\n",
    "logger.info(f\"Training images: {train_images}, Val GT: {val_gt_images}, Val LQ: {val_lq_images}, Test: {test_images}\")\n",
    "if train_images == 0 or val_gt_images == 0 or val_lq_images == 0:\n",
    "    raise ValueError(\"Dataset directories are empty.\")\n",
    "\n",
    "# Generate Meta Info\n",
    "with open(opt['meta_info'], 'w') as f:\n",
    "    for fname in sorted(os.listdir('/content/FFHQ/train/GT')):\n",
    "        if fname.endswith('.png'):\n",
    "            f.write(f\"{fname}\\n\")\n",
    "with open('/content/FFHQ/val/meta_info_FFHQval_GT.txt', 'w') as f:\n",
    "    for fname in sorted(os.listdir('/content/FFHQ/val/GT')):\n",
    "        if fname.endswith('.png'):\n",
    "            f.write(f\"{fname}\\n\")\n",
    "\n",
    "# DataLoaders\n",
    "train_dataset = FFHQsubDataset(opt)\n",
    "val_dataset = FFHQsubDataset({\n",
    "    **opt,\n",
    "    'dataroot_gt': '/content/FFHQ/val/GT',\n",
    "    'meta_info': '/content/FFHQ/val/meta_info_FFHQval_GT.txt',\n",
    "    'use_hflip': False,\n",
    "    'use_rot': False\n",
    "})\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2, pin_memory=True)\n",
    "logger.info(f\"Train samples: {len(train_dataset)}, Validation samples: {len(val_dataset)}\")\n",
    "\n",
    "# Training Setup\n",
    "model = FaceRestormer().to(device)\n",
    "params = sum(p.numel() for p in model.parameters())\n",
    "logger.info(f\"Model parameters: {params}\")\n",
    "assert params < 250000, f\"Model exceeds parameter limit: {params.sum()}}\"\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, (nn.Conv2dnn.Linear)):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias_, 0)\n",
    "\n",
    "model.apply(init_weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "criterion_l1 = nn.L1Loss()\n",
    "criterion_perceptual = PerceptualLoss()\n",
    "scaler = GradScaler()\n",
    "writer = SummaryWriter(\"runs/face_restormer\")\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 15\n",
    "best_psnr = 0\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    for data in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        gt = data['gt'].to(device)\n",
    "        kernel = data['kernel'].to(device)\n",
    "        sinc_kernel = data['sinc_kernel'].to(device)\n",
    "        lq = degrade_image(gt, kernel, sinc_kernel)\n",
    "        landmark_heatmap = generate_landmark_heatmap(lq)\n",
    "\n",
    "        with autocast():\n",
    "            pred = model(lq, landmark_heatmap)\n",
    "            loss_l1 = criterion_l1(pred, gt)\n",
    "            loss_perceptual = criterion_perceptual(pred, gt)\n",
    "            loss_landmark = criterion_l1(pred * F.interpolate(landmark_heatmap, size=(512, 512), mode='bilinear'), gt * F.interpolate(landmark_heatmap, size=(512, 512), mode='bilinear'))\n",
    "            loss = 0.5 * loss_l1 + 0.3 * loss_perceptual + 0.2 * loss_landmark\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    avg_train_loss = epoch_loss / num_batches\n",
    "    logger.info(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, LR: {scheduler.get_last_lr()[0]:.2e}\")\n",
    "    writer.add_scalar('Loss/train', avg_train_loss, epoch)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    psnr_list = []\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            gt = data['gt'].to(device)\n",
    "            kernel = data['kernel'].to(device)\n",
    "            sinc_kernel = data['sinc_kernel'].to(device)\n",
    "            lq = degrade_image(gt, kernel, sinc_kernel)\n",
    "            landmark_heatmap = generate_landmark_heatmap(lq)\n",
    "            pred = model(lq, landmark_heatmap)\n",
    "            for i in range(pred.size(0)):\n",
    "                pred_np = (pred[i].permute(1, 2, 0.cpu().numpy() * 255).astype(np.uint8)\n",
    "                gt_np = (gt[i].permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)\n",
    "                mse = np.mean((pred_np - gt_np) ** 2))\n",
    "                psnr = 20 * np.log10(255 / np.sqrt(mse)) if mse > 0 else 100\n",
    "                psnr_list.append(psnr)\n",
    "                Image.fromarray(pred_np).save(f\"/content/results/val/{len(psnr_list):04d}.png\")\n",
    "\n",
    "    mean_psnr = np.mean(psnr_list)\n",
    "    logger.info(f\"Epoch {epoch+1}/{num_epochs}, Validation PSNR: {mean_psnr:.2f} dB\")\n",
    "    if mean_psnr > best_psnr:\n",
    "        best_psnr = mean_psnr\n",
    "        best_epoch = epoch + 1\n",
    "        torch.save(model.state_dict(), \"/content/models/face_restormer_best.pth\")\n",
    "\n",
    "    writer.add_scalar('PSNR/val', mean_psnr, epoch)\n",
    "\n",
    "torch.save(model.state_dict(), \"/content/models/face_restormer_final.pth\")\n",
    "logger.info(f\"Training completed. Best PSNR: {best_psnr:.2f} dB at epoch {best_epoch}\")\n",
    "\n",
    "# Inference\n",
    "model.load_state_dict(torch.load(\"/content/models/face_restormer_best.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Validation Inference\n",
    "psnr_list = []\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(val_loader, desc=\"Validation Inference\"):\n",
    "        gt = data['gt'].to(device)\n",
    "        kernel = data['kernel'].to(device)\n",
    "        sinc_kernel = data['sinc_kernel'].to(device)\n",
    "        lq = degrade_image(gt, kernel, sinc_kernel)\n",
    "        landmark_heatmap = generate_landmark_heatmap(lq)\n",
    "        pred = model(lq, landmark_heatmap)\n",
    "        for i in range(pred.shape[0]):\n",
    "            pred_np = (pred[i].squeeze().permute(1, 2, 0).cpu().cpu().numpy() * 255).clip(0, 255).astype(np.uint8)\n",
    "            gt_np = (gt[i].permute(1, 2, 0).cpu().cpu().numpy() * 255).astype(np.uint8)\n",
    "            mse = np.mean((pred_np - gt_np) ** 2))\n",
    "            psnr = 20 * np.log10(255 / np.sqrt(mse)) if mse > 0 else 100\n",
    "            psnr_list.append(psnr)\n",
    "            Image.fromarray(pred_np).save(f\"/content/results/val/{len(psnr_list):04d}.png\")\n",
    "\n",
    "mean_psnr = np.mean(psnr_list)\n",
    "with open(\"/content/results/val/scores.txt\", 'w') as f:\n",
    "    f.write(f\"PSNR: {mean_psnr:.4f}\")\n",
    "logger.info(f\"Validation PSNR: {mean_psnr:.2f} dB\")\n",
    "\n",
    "# Test Inference\n",
    "test_dir = \"/content/FFHQ/test/LQ\"\n",
    "if os.path.exists(test_dir) and os.listdir(test_dir):\n",
    "    test_files = sorted([f for f in os.listdir(test_dir) if f.endswith('.png')])\n",
    "    with torch.no_grad():\n",
    "        for fname in tqdm(test_files, desc=\"Test Images\"):\n",
    "            img = Image.open(os.path.join(test_dir, fname)).convert('RGB').resize((128, 128))\n",
    "            lq = img2tensor(np.array(img), bgr2rgb=True, float32=True).unsqueeze(0).to(device)\n",
    "            landmark_heatmap = generate_landmark_heatmap(lq)\n",
    "            pred = model(lq, landmark_heatmap)\n",
    "            pred_np = (pred.squeeze().squeeze().permute(1, 2, 0).cpu().numpy() * 255).clip(0, 255).astype(np.uint8)\n",
    "            Image.fromarray(pred_np).write(f\"/content/results/test/{fname}\")\n",
    "    logger.info(\"Test predictions saved\")\n",
    "else:\n",
    "    logger.warning(f\"No test set available at {test_dir}\")\n",
    "\n",
    "# Submission Prep\n",
    "os.makedirs('/content/submit', exist_ok=True)\n",
    "os.makedirs('/content/adx/src', exist_ok=True)\n",
    "os.makedirs('/content/adx/logs', exist_ok=True)\n",
    "os.system(f\"cp /content/results/test/*.png /content/submit/ || echo 'No test results to copy'\")\n",
    "os.system('zip -r /content/submit.zip /content/submit/')\n",
    "os.system(f\"cp /content/results/val/*.png /content/adx/ || echo 'No validation results'\")\n",
    "os.system(f\"cp /content/results/val/scores.txt /content/adx/codalab_score.txt || echo 'No scores.txt'\")\n",
    "os.system(f\"cp /content/models/face_restormer_best.pth /content/adx/\")\n",
    "os.system(f\"cp -r /content/runs/face_restormer/* /content/adx/logs/ || echo 'No logs'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bd77c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
